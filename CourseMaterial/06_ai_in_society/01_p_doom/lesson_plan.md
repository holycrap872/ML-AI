## Essential Questions

- What level of risk is acceptable when pursing a better world?
- What are capabilities that AI should not have?

## Lesson Plan

### Setup

- Paper clip -> end of the world article
    - https://nickbostrom.com/ethics/ai
- Section from US government's AI document

### Actual Lesson

- Review
    - Economics of data
    - Debrief about quality of discussion and expectations
    - Any new thoughts?
- P-doom review
    - What was the article trying to say?
    - What is your p-doom?
    - Quiz: what do you think the p-doom for various famous people are
        - Temporary OpenAI CEO
            - 50% on a bad day
        - Anthropic CEO
            - 10-25%
        - Elon Musk
            - Allegedly 20-30 (https://www.fastcompany.com/90994526)
- Today, going to create own "rube goldberg for destruction"
    - In pairs
    - The more complex the better
    - Go!
- Go through everyone's ten step plan for the end of the world
    - Which seems to be the most likely?
    - Any common themes?
- Show OpenAI red team chart
    - Find your favorite
        - Discuss
    - Find 2-3 tests that would neuter your scenario
    - More discussion
- Ground homework reading
    - Discussion about ethical use of AI in society
        - Predictive algorithms
        - Identification algorithms
        - Scale: meter maid vs. new police cars that auto-run plates
    - Initial thoughts?

#### Homework

Read next day's discussion article

#### Resources

- https://www.decisionproblem.com/paperclips/index2.html
    - Use neural resonant frequencies to influence shoppers
- https://cepr.org/voxeu/columns/ai-and-paperclip-problem