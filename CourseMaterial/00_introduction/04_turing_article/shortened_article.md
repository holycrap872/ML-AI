## 1. The Imitation Game

I propose to consider the question, "Can machines think?" This should begin with
definitions of the meaning of the terms "machine" and "think." The definitions might be
framed so as to reflect so far as possible the normal use of the words, but this attitude is
dangerous, If the meaning of the words "machine" and "think" are to be found by
examining how they are commonly used it is difficult to escape the conclusion that the
meaning and the answer to the question, "Can machines think?" is to be sought in a
statistical survey such as a Gallup poll. But this is absurd. Instead of attempting such a
definition I shall replace the question by another, which is closely related to it and is
expressed in relatively unambiguous words.

The new form of the problem can be described in terms of a game which we call the
"imitation game."

...

## 6. Contrary Views on the Main Question

...

It will simplify matters for the reader if I explain first my own beliefs in the matter.
Consider first the more accurate form of the question. I believe that in about fifty years
time it will be possible, to programme computers, with a storage capacity of about 10^9, to
make them play the imitation game so well that an average interrogator will not have
more than 70 per cent chance of making the right identification after five minutes of
questioning. The original question, "Can machines think?" I believe to be too
meaningless to deserve discussion. Nevertheless I believe that at the end of the century
the use of words and general educated opinion will have altered so much that one will be
able to speak of machines thinking without expecting to be contradicted. I believe further
that no useful purpose is served by concealing these beliefs. The popular view that
scientists proceed inexorably from well-established fact to well-established fact, never
being influenced by any improved conjecture, is quite mistaken. Provided it is made clear
which are proved facts and which are conjectures, no harm can result. Conjectures are of
great importance since they suggest useful lines of research.

...

## Learning Machines

...

In the process of trying to imitate an adult human mind we are bound to think a good deal
about the process which has brought it to the state that it is in. We may notice three
components.

1. The initial state of the mind, say at birth,
2. The education to which it has been subjected,
3. Other experience, not to be described as education, to which it has been subjected.

Instead of trying to produce a programme to simulate the adult mind, why not rather try
to produce one which simulates the child's? If this were then subjected to an appropriate
course of education one would obtain the adult brain. Presumably the child brain is
something like a notebook as one buys it from the stationer's. Rather little mechanism,
and lots of blank sheets. (Mechanism and writing are from our point of view almost
synonymous.) Our hope is that there is so little mechanism in the child brain that
something like it can be easily programmed. The amount of work in the education we can
assume, as a first approximation, to be much the same as for the human child.
We have thus divided our problem into two parts. The child programme and the
education process. These two remain very closely connected. We cannot expect to find a
good child machine at the first attempt. One must experiment with teaching one such
machine and see how well it learns. One can then try another and see if it is better or
worse. There is an obvious connection between this process and evolution, by the
identifications

- Structure of the child machine = hereditary material
- Changes of the child machine = mutation,
- Natural selection = judgment of the experimenter

One may hope, however, that this process will be more expeditious than evolution. The
survival of the fittest is a slow method for measuring advantages. The experimenter, by
the exercise of intelligence, should he able to speed it up. Equally important is the fact
that he is not restricted to random mutations. If he can trace a cause for some weakness
he can probably think of the kind of mutation which will improve it.

It will not be possible to apply exactly the same teaching process to the machine as to a
normal child. It will not, for instance, be provided with legs, so that it could not be asked
to go out and fill the coal scuttle. Possibly it might not have eyes. But however well these
deficiencies might be overcome by clever engineering, one could not send the creature to
school without the other children making excessive fun of it. It must be given some
tuition. We need not be too concerned about the legs, eyes, etc. The example of Miss
Helen Keller shows that education can take place provided that communication in both
directions between teacher and pupil can take place by some means or other.

We normally associate punishments and rewards with the teaching process. Some simple
child machines can be constructed or programmed on this sort of principle. The machine
has to be so constructed that events which shortly preceded the occurrence of a
punishment signal are unlikely to be repeated, whereas a reward signal increased the
probability of repetition of the events which led up to it.

...

Opinions may vary as to the complexity which is suitable in the child machine. One
might try to make it as simple as possible consistently with the general principles.
Alternatively one might have a complete system of logical inference "built in." In the
latter case the store would be largely occupied with definitions and propositions. The
propositions would have various kinds of status, e.g., well-established facts, conjectures,
mathematically proved theorems, statements given by an authority, expressions having
the logical form of proposition but not belief-value. Certain propositions may be
described as "imperatives." The machine should be so constructed that as soon as an
imperative is classed as "well established" the appropriate action automatically takes
place. To illustrate this, suppose the teacher says to the machine, "Do your homework
now." This may cause "Teacher says 'Do your homework now'" to be included amongst
the well-established facts. Another such fact might be, "Everything that teacher says is
true." Combining these may eventually lead to the imperative, "Do your homework now,"
being included amongst the well-established facts, and this, by the construction of the
machine, will mean that the homework actually gets started, but the effect is very
satisfactory. The processes of inference used by the machine need not be such as would
satisfy the most exacting logicians. There might for instance be no hierarchy of types. But
this need not mean that type fallacies will occur, any more than we are bound to fall over
unfenced cliffs. Suitable imperatives (expressed within the systems, not forming part of
the rules of the system) such as "Do not use a class unless it is a subclass of one which
has been mentioned by teacher" can have a similar effect to "Do not go too near the
edge."

The imperatives that can be obeyed by a machine that has no limbs are bound to be of a
rather intellectual character, as in the example (doing homework) given above. important
amongst such imperatives will be ones which regulate the order in which the rules of the
logical system concerned are to be applied, For at each stage when one is using a logical
system, there is a very large number of alternative steps, any of which one is permitted to
apply, so far as obedience to the rules of the logical system is concerned. These choices
make the difference between a brilliant and a footling reasoner, not the difference
between a sound and a fallacious one. Propositions leading to imperatives of this kind
might be "When Socrates is mentioned, use the syllogism in Barbara" or "If one method
has been proved to be quicker than another, do not use the slower method." Some of
these may be "given by authority," but others may be produced by the machine itself, e.g.
by scientific induction.

The idea of a learning machine may appear paradoxical to some readers. How can the
rules of operation of the machine change? They should describe completely how the
machine will react whatever its history might be, whatever changes it might undergo. The
rules are thus quite time-invariant. This is quite true. The explanation of the paradox is
that the rules which get changed in the learning process are of a rather less pretentious
kind, claiming only an ephemeral validity. The reader may draw a parallel with the
Constitution of the United States.

An important feature of a learning machine is that its teacher will often be very largely
ignorant of quite what is going on inside, although he may still be able to some extent to
predict his pupil's behavior. This should apply most strongly to the later education of a
machine arising from a child machine of well-tried design (or programme). This is in
clear contrast with normal procedure when using a machine to do computations one's
object is then to have a clear mental picture of the state of the machine at each moment in
the computation. This object can only be achieved with a struggle. The view that "the
machine can only do what we know how to order it to do," appears strange in face of
this. Most of the programmes which we can put into the machine will result in its doing
something that we cannot make sense (if at all, or which we regard as completely random
behaviour. Intelligent behaviour presumably consists in a departure from the completely
disciplined behaviour involved in computation, but a rather slight one, which does not
give rise to random behaviour, or to pointless repetitive loops. Another important result
of preparing our machine for its part in the imitation game by a process of teaching and
learning is that "human fallibility" is likely to be omitted in a rather natural way, i.e.,
without special "coaching." ... Processes that are learnt do not produce a hundred percent
certainty of result; if they did they could not be unlearnt.

It is probably wise to include a random element in a learning machine. A random element
is rather useful when we are searching for a solution of some problem. Suppose for
instance we wanted to find a number between 50 and 200 which was equal to the square
of the sum of its digits, we might start at 51 then try 52 and go on until we got a number
that worked. Alternatively we might choose numbers at random until we got a good one.
This method has the advantage that it is unnecessary to keep track of the values that have
been tried, but the disadvantage that one may try the same one twice, but this is not very
important if there are several solutions. The systematic method has the disadvantage that
there may be an enormous block without any solutions in the region which has to be
investigated first, Now the learning process may be regarded as a search for a form of
behaviour which will satisfy the teacher (or some other criterion). Since there is probably
a very large number of satisfactory solutions the random method seems to be better than
the systematic. It should be noticed that it is used in the analogous process of evolution.
But there the systematic method is not possible. How could one keep track of the
different genetical combinations that had been tried, so as to avoid trying them again?
We may hope that machines will eventually compete with men in all purely intellectual
fields. But which are the best ones to start with? Even this is a difficult decision. Many
people think that a very abstract activity, like the playing of chess, would be best. It can
also be maintained that it is best to provide the machine with the best sense organs that
money can buy, and then teach it to understand and speak English. This process could
follow the normal teaching of a child. Things would be pointed out and named, etc.
Again I do not know what the right answer is, but I think both approaches should be tried.

We can only see a short distance ahead, but we can see plenty there that needs to be done

